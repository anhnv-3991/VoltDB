# Overview

Create an absolutely naive 2 day prototype of VoltDB using

on disk storage.

## Install leveldb / leveldbjni

John added a LevelDB JNI wrapper to github. Download those jarfiles and
add them to the voltdb/lib or voltdb/voltdb directories.

## Modify VoltDB

I modified VoltProcedure to make the m_site variable protected, allowing
user authored procedures access to the execution site. I added an accessor
to a leveldb api/database instance via the SiteProcedureConnection
interface.  Finally, I initialized per-site leveldb instances in the
ExecutionSite constructor.

diff --git a/src/frontend/org/voltdb/ExecutionSite.java b/src/frontend/org/voltdb/ExecutionSite.java
index aab76fb..c45d929 100644
--- a/src/frontend/org/voltdb/ExecutionSite.java
+++ b/src/frontend/org/voltdb/ExecutionSite.java
@@ -2345,4 +2345,9 @@ implements Runnable, SiteTransactionConnection, SiteProcedureConnection
             }
         }
     }
+
+    @Override
+    public DB getLevelDBInstance() {
+        return m_db;
+    }
 }


@@ -643,6 +647,10 @@ implements Runnable, SiteTransactionConnection, SiteProcedureConnection

     SystemProcedureContext m_systemProcedureContext;

+    // for ENG-1969 testing: a reference to a leveldb database.
+    // each execution site creates its own database.
+    public DB m_db;

@@ -742,6 +750,21 @@ implements Runnable, SiteTransactionConnection, SiteProcedureConnection
                                        Integer.parseInt(getCorrespondingCatalogSite().getTypeName()),
                                        m_indexStats);

+        initializeLevelDB();
+    }
+
+    private void initializeLevelDB()
+    {
+        hostLog.info("Initializing levelDB for site " + m_siteId);
+        try {
+            Options options = new Options();
+            options.createIfMissing(true);
+            JniDBFactory factory = new JniDBFactory();
+            m_db = factory.open(new File("/tmp/leveldb-" + m_siteId), options);
+        } catch (Exception e) {
+            hostLog.fatal("Failed to create database with exception: ", e);
+            VoltDB.crashGlobalVoltDB("Failed to create leveldb intance.", false, null);
+        }
     }



## Application

The application manages a (groupid, rowid, access time, payload) dataset.
There are 100,001 groups (0...100,000) with 1000 rowids per group (0..999).

The loader writes keys only to leveldb - leaving a 100% cold cache. This is
done by repeated calls to CreateKey.java stored procedure.

The load generator updates payloads and access times for a random (rowid_group,
rowid). If the group is not present in ram, it is loaded from disk. If
more than MAX_GROUPS (1000) rowid_groups are present at the partition, the
rowid_group with the smallest access time (txn id) is fully evicted and
written back to disk.

The application is runnable via ./run.sh. You can control the loader by
setting run-loader to false/true in the run.sh AsyncBenchmark script.


## Initial findings

 * Integration was relatively simple. It is easy to manage this logic
   from with a stored procedure. LevelDB is trivial to use.

 * Throughput: with all local work and the full dataset in RAM, my
   desktop managed 25,000 UpdateKey transactions / second.

 * Latency: doing the leveldb seeks blocking at the site destroys
   latency. I suspect the depth of the volt pipeline is at fault here,
   even with 1% cold data accesses, there may be as many 500 leveldb
   seeks in the full pipeline.

   A deeper investigation in latency distribution / percentiles is
   necessary.

 * Testing: I evaluated correctness by manually observing the grouped
   view contents, observing how many rowid_groups are GTE to 4000 (the
   hot data set) and verifying that the oldest accessed group is changing
   (as it is the evicted group).





